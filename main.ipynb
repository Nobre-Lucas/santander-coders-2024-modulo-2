{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/yari/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: snowflake-connector-python in /Users/yari/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.10.1)\n",
      "Requirement already satisfied: snowflake-snowpark-python in /Users/yari/anaconda3/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.21.0)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (1.15.1)\n",
      "Requirement already satisfied: cryptography<43.0.0,>=3.1.0 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (39.0.1)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (23.0.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: pytz in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (2022.7)\n",
      "Requirement already satisfied: requests<3.0.0 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (2.28.1)\n",
      "Requirement already satisfied: packaging in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (4.10.0)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (3.9.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (4.2.2)\n",
      "Requirement already satisfied: tomlkit in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python->-r requirements.txt (line 2)) (0.11.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: pyarrow in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-connector-python[pandas]->-r requirements.txt (line 3)) (17.0.0)\n",
      "Requirement already satisfied: setuptools>=40.6.0 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-snowpark-python->-r requirements.txt (line 4)) (67.6.1)\n",
      "Requirement already satisfied: wheel in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-snowpark-python->-r requirements.txt (line 4)) (0.38.4)\n",
      "Requirement already satisfied: pyyaml in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-snowpark-python->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: cloudpickle!=2.1.0,!=2.2.0,<=2.2.1,>=1.6.0 in /Users/yari/anaconda3/lib/python3.10/site-packages (from snowflake-snowpark-python->-r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Users/yari/anaconda3/lib/python3.10/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python->-r requirements.txt (line 2)) (2.21)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/yari/anaconda3/lib/python3.10/site-packages (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas]->-r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yari/anaconda3/lib/python3.10/site-packages (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas]->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yari/anaconda3/lib/python3.10/site-packages (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas]->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yari/anaconda3/lib/python3.10/site-packages (from requests<3.0.0->snowflake-connector-python->-r requirements.txt (line 2)) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yari/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas]->-r requirements.txt (line 3)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run logging.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run schema.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run snowflake_connection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_raw_table.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run create_table.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2b5afd7-77fe-4d5c-a286-8a297a836d67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Logger():\n",
    "#     def __init__(self):\n",
    "#         self.format = '%(asctime)s - %(levelname)s - %(message)s'\n",
    "\n",
    "\n",
    "#     def set_logger(self):\n",
    "#         logging.basicConfig(format=self.format, level=logging.INFO)\n",
    "#         logger = logging.getLogger()\n",
    "\n",
    "#         return logger   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SnowflakeHandler(SnowflakeConnector):\n",
    "#     \"\"\"\n",
    "#     Classe para gerenciar a conexão e operações com Snowflake.\n",
    "\n",
    "#     Atributos:\n",
    "#     ----------\n",
    "#     user: str\n",
    "#         Nome do usuário para a conexão com Snowflake.\n",
    "#     password: str\n",
    "#         Senha do usuário para a conexão com Snowflake.\n",
    "#     account: str\n",
    "#         Identificador da conta Snowflake.\n",
    "#     warehouse: str\n",
    "#         Nome do warehouse a ser usado na conexão.\n",
    "#     database: str\n",
    "#         Nome do banco de dados a ser usado na conexão.\n",
    "#     schema: str\n",
    "#         Nome do schema a ser usado na conexão.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         \"\"\"\n",
    "#         Inicializa a classe SnowflakeHandler carregando as variáveis de ambiente.\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.logger_class = Logger()\n",
    "#         self.logger = self.logger_class.set_logger()        \n",
    "\n",
    "#     # def connect(self):\n",
    "#     #     \"\"\"\n",
    "#     #     Estabelece uma conexão com Snowflake usando a configuração fornecida.\n",
    "        \n",
    "#     #     Retorna:\n",
    "#     #     --------\n",
    "#     #     None\n",
    "#     #     \"\"\"\n",
    "\n",
    "#     #     SNOWFLAKE_CONFIG = {\n",
    "#     #         'user': self.user,\n",
    "#     #         'password': self.password,\n",
    "#     #         'account': self.account,\n",
    "#     #         'warehouse': self.warehouse,\n",
    "#     #         'database': self.database,\n",
    "#     #         'schema': self.schema\n",
    "#     #     }        \n",
    "#     #     print(SNOWFLAKE_CONFIG) \n",
    "          \n",
    "#     #     self.session = Session.builder.configs(SNOWFLAKE_CONFIG).create()\n",
    "\n",
    "#     # def close_connection(self):\n",
    "#     #     \"\"\"\n",
    "#     #     Fecha a conexão com Snowflake.\n",
    "        \n",
    "#     #     Retorna:\n",
    "#     #     --------\n",
    "#     #     None\n",
    "#     #     \"\"\"\n",
    "#     #     if self.session is not None:\n",
    "#     #         self.session.close()\n",
    "\n",
    "#     def save_dataframe(self, df: pd.DataFrame, table_name: str, column_names: list) -> None:\n",
    "#         \"\"\"\n",
    "#         Salva um DataFrame no Snowflake, sobrescrevendo o conteúdo da tabela.\n",
    "\n",
    "#         Parâmetros:\n",
    "#         -----------\n",
    "#         df: pd.DataFrame\n",
    "#             O DataFrame que será salvo no Snowflake.\n",
    "#         table_name: str\n",
    "#             O nome da tabela onde o DataFrame será salvo.\n",
    "#         column_names: list\n",
    "#             Lista de nomes das colunas que devem ser usadas no DataFrame.\n",
    "        \n",
    "#         Retorna:\n",
    "#         --------\n",
    "#         None\n",
    "#         \"\"\"\n",
    "#         super().connect()\n",
    "\n",
    "#         if not self.connection or not self.cursor:\n",
    "#             raise RuntimeError(\"Conexão com Snowflake não estabelecida.\")\n",
    "             \n",
    "#         df.columns = column_names\n",
    "\n",
    "#         # Limpar aspas e espaços desnecessários dos nomes das colunas\n",
    "#         df.columns = df.columns.str.replace(r'^\"|\"$', '', regex=True).str.strip()\n",
    "\n",
    "#         # Apagar o conteúdo existente na tabela\n",
    "#         try:\n",
    "#             self.cursor.execute(f\"DELETE FROM {table_name}\")\n",
    "#             self.logger.info(f\"Conteúdo da tabela '{table_name}' deletado com sucesso.\")\n",
    "#         except Exception as e:\n",
    "#             self.logger.error(f\"Erro ao deletar o conteúdo da tabela '{table_name}': {e}\")\n",
    "#             raise\n",
    "\n",
    "#         # Inserir o novo DataFrame na tabela\n",
    "#         success, nchunks, nrows, _ = write_pandas(self.connection, df, table_name)\n",
    "\n",
    "#         if success:\n",
    "#             self.logger.info(f\"DataFrame salvo com sucesso na tabela '{table_name}'. Total de linhas: {nrows}.\")\n",
    "#         else:\n",
    "#             self.logger.error(f\"Falha ao salvar o DataFrame na tabela '{table_name}'.\")\n",
    "\n",
    "#         super().disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "910a4984-cefd-4e97-9f38-fd466477df43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class UrbanMobilityData:\n",
    "    def __init__(self, url: str):\n",
    "        \"\"\"\n",
    "        Inicializa a classe com a URL do arquivo zip.\n",
    "\n",
    "        :param url: URL do arquivo zipado do Kaggle.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.file_paths = {\n",
    "            \"Household\": \"Household.csv\",\n",
    "            \"Person\": \"Person.csv\",\n",
    "            \"Stage\": \"Stage.csv\",\n",
    "            \"Trip\": \"Trip.csv\"\n",
    "        }\n",
    "        self.logger_class = Logger()\n",
    "        self.logger = self.logger_class.set_logger()            \n",
    "\n",
    "    def download_zip(self) -> Optional[bytes]:\n",
    "        \"\"\"\n",
    "        Faz o download do arquivo zipado da URL fornecida.\n",
    "\n",
    "        :return: Conteúdo do arquivo zipado em bytes, ou None em caso de erro.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.url)\n",
    "            if response.status_code == 200:\n",
    "                return response.content\n",
    "            else:\n",
    "                self.logger.error(f\"Falha ao fazer o download dos arquivos. Status code: {response.status_code}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro ao baixar o arquivo: {e}\")\n",
    "            return None\n",
    "\n",
    "    def extract_zip_to_dataframes(self, zip_content: bytes) -> Dict[str, Optional[pd.DataFrame]]:\n",
    "        \"\"\"\n",
    "        Extrai o conteúdo do arquivo zipado e carrega os arquivos CSV em DataFrames.\n",
    "\n",
    "        :param zip_content: Conteúdo do arquivo zipado em bytes.\n",
    "        :return: Dicionário onde as chaves são os nomes dos arquivos e os valores são os DataFrames ou None.\n",
    "        \"\"\"\n",
    "        dataframes = {}\n",
    "        try:\n",
    "            with zipfile.ZipFile(io.BytesIO(zip_content), 'r') as zip_ref:\n",
    "                for file_name in zip_ref.namelist():\n",
    "                    if file_name in self.file_paths.values():\n",
    "                        with zip_ref.open(file_name) as file:\n",
    "                            df = pd.read_csv(file, sep=';', on_bad_lines='skip')\n",
    "                            key = [k for k, v in self.file_paths.items() if v == file_name][0]\n",
    "                            dataframes[key] = df\n",
    "                            self.logger.info(f\"DataFrame {key} carregado com sucesso\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro ao processar o arquivo zipado: {e}\")\n",
    "        return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 14:33:56,321 - INFO - DataFrame Household carregado com sucesso\n",
      "2024-09-07 14:33:56,719 - INFO - DataFrame Person carregado com sucesso\n",
      "2024-09-07 14:33:57,096 - INFO - DataFrame Stage carregado com sucesso\n",
      "2024-09-07 14:33:58,314 - INFO - DataFrame Trip carregado com sucesso\n",
      "2024-09-07 14:33:58,343 - INFO - Household\n",
      "2024-09-07 14:33:58,347 - INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.10.9, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "2024-09-07 14:33:58,348 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2024-09-07 14:33:59,558 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:33:59,560 - INFO - closed\n",
      "2024-09-07 14:33:59,701 - INFO - No async queries seem to be running, deleting session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela HOUSEHOLD criada com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 14:33:59,855 - INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.10.9, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "2024-09-07 14:33:59,856 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2024-09-07 14:34:01,891 - INFO - Conteúdo da tabela 'HOUSEHOLD' deletado com sucesso.\n",
      "2024-09-07 14:34:02,168 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:06,684 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:06,686 - INFO - DataFrame salvo com sucesso na tabela 'HOUSEHOLD'. Total de linhas: 19252.\n",
      "2024-09-07 14:34:06,688 - INFO - closed\n",
      "2024-09-07 14:34:06,852 - INFO - No async queries seem to be running, deleting session\n",
      "2024-09-07 14:34:07,037 - INFO - Person\n",
      "2024-09-07 14:34:07,038 - INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.10.9, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "2024-09-07 14:34:07,039 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2024-09-07 14:34:08,466 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:08,467 - INFO - closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela PERSON criada com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 14:34:08,669 - INFO - No async queries seem to be running, deleting session\n",
      "2024-09-07 14:34:08,979 - INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.10.9, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "2024-09-07 14:34:08,980 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2024-09-07 14:34:10,452 - INFO - Conteúdo da tabela 'PERSON' deletado com sucesso.\n",
      "2024-09-07 14:34:10,774 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:14,610 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:14,611 - INFO - DataFrame salvo com sucesso na tabela 'PERSON'. Total de linhas: 61358.\n",
      "2024-09-07 14:34:14,611 - INFO - closed\n",
      "2024-09-07 14:34:14,813 - INFO - No async queries seem to be running, deleting session\n",
      "2024-09-07 14:34:14,999 - INFO - Stage\n",
      "2024-09-07 14:34:15,001 - INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.10.9, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "2024-09-07 14:34:15,005 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2024-09-07 14:34:16,146 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:16,146 - INFO - closed\n",
      "2024-09-07 14:34:16,326 - INFO - No async queries seem to be running, deleting session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela STAGE criada com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 14:34:16,481 - INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.10.9, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "2024-09-07 14:34:16,483 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2024-09-07 14:34:17,812 - INFO - Conteúdo da tabela 'STAGE' deletado com sucesso.\n",
      "2024-09-07 14:34:18,111 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:22,641 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:22,643 - INFO - DataFrame salvo com sucesso na tabela 'STAGE'. Total de linhas: 117730.\n",
      "2024-09-07 14:34:22,646 - INFO - closed\n",
      "2024-09-07 14:34:22,809 - INFO - No async queries seem to be running, deleting session\n",
      "2024-09-07 14:34:22,970 - INFO - Trip\n",
      "2024-09-07 14:34:22,971 - INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.10.9, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "2024-09-07 14:34:22,972 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2024-09-07 14:34:24,653 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:24,654 - INFO - closed\n",
      "2024-09-07 14:34:24,850 - INFO - No async queries seem to be running, deleting session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela TRIP criada com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 14:34:25,061 - INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.10.9, Platform: macOS-10.16-x86_64-i386-64bit\n",
      "2024-09-07 14:34:25,062 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2024-09-07 14:34:27,026 - INFO - Conteúdo da tabela 'TRIP' deletado com sucesso.\n",
      "2024-09-07 14:34:27,420 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:36,453 - INFO - Number of results in first chunk: 1\n",
      "2024-09-07 14:34:36,454 - INFO - DataFrame salvo com sucesso na tabela 'TRIP'. Total de linhas: 113398.\n",
      "2024-09-07 14:34:36,455 - INFO - closed\n",
      "2024-09-07 14:34:36,624 - INFO - No async queries seem to be running, deleting session\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    url = os.getenv(\"URL\")\n",
    "    logger_class = Logger()\n",
    "    logger = logger_class.set_logger()    \n",
    "    data_handler = UrbanMobilityData(url)\n",
    "    create_table = SnowflakeTableCreator()\n",
    "\n",
    "\n",
    "    # Fazendo o download do arquivo zip\n",
    "    zip_content = data_handler.download_zip()\n",
    "    if zip_content:\n",
    "        # Extraindo o conteúdo do arquivo zip e carregando os DataFrames\n",
    "        dataframes = data_handler.extract_zip_to_dataframes(zip_content)\n",
    "\n",
    "        for name, df in dataframes.items():\n",
    "            if df is not None:\n",
    "                logger.info(name)\n",
    "\n",
    "                handler = SnowflakeHandlerRaw()\n",
    "                # handler.connect()\n",
    "                # create_table.connect()\n",
    "\n",
    "                target_table_location = name.upper()\n",
    "\n",
    "                match name.upper():\n",
    "                    case 'PERSON':\n",
    "                        create_table.create_table(target_table_location, table_person)\n",
    "                    case 'HOUSEHOLD':\n",
    "                        create_table.create_table(target_table_location, table_household)\n",
    "                    case 'STAGE':\n",
    "                        create_table.create_table(target_table_location, table_stage)\n",
    "                    case 'TRIP':\n",
    "                        create_table.create_table(target_table_location, table_trip)\n",
    "\n",
    "                # create_table.disconnect()\n",
    "\n",
    "                expected_columns = [c.upper() for c in df.columns]\n",
    "\n",
    "                handler.save_dataframe(df, target_table_location, expected_columns)\n",
    "        \n",
    "                # handler.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "main",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
